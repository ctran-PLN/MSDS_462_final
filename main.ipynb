{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style Transfer with OpenVINOâ„¢ Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules.\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/intel-software-innovators/neural-style-transfer-with-open-vino-toolkit-b56ae7c6a2c\n",
    "#source /opt/intel/openvino/bin/setupvars.sh\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Imported Python modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters settings:\n",
      "\tmodel_xml= ./nst_vgg19/nst_vgg19-symbol.xml \n",
      "\tmodel_bin= ./nst_vgg19/nst_vgg19-symbol.bin \n",
      "\tinput_path= ../images/tubingen.jpg \n",
      "\tcpu_extension_path= libcpu_extension.so \n",
      "\tdevice= MYRIAD \n",
      "\tmean_val_r= 123.68 \n",
      "\tmean_val_g= 116.779 \n",
      "\tmean_val_b= 103.939\n"
     ]
    }
   ],
   "source": [
    "# model IR files\n",
    "model_xml = \"./nst_vgg19/nst_vgg19-symbol.xml\"\n",
    "model_bin = \"./nst_vgg19/nst_vgg19-symbol.bin\"\n",
    "# input image file\n",
    "input_path = \"../images/tubingen.jpg\"\n",
    "# CPU extension library to use\n",
    "cpu_extension_path = \"libcpu_extension.so\"\n",
    "# device to use\n",
    "device = \"MYRIAD\"\n",
    "# RGB mean values to add to results\n",
    "mean_val_r = 123.68\n",
    "mean_val_g = 116.779\n",
    "mean_val_b = 103.939\n",
    "print(\"Configuration parameters settings:\"\n",
    "\"\\n\\tmodel_xml=\", model_xml,\n",
    "\"\\n\\tmodel_bin=\", model_bin,\n",
    "\"\\n\\tinput_path=\", input_path,\n",
    "\"\\n\\tcpu_extension_path=\", cpu_extension_path,\n",
    "\"\\n\\tdevice=\", device,\n",
    "\"\\n\\tmean_val_r=\", mean_val_r,\n",
    "\"\\n\\tmean_val_g=\", mean_val_g,\n",
    "\"\\n\\tmean_val_b=\", mean_val_b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Plugin for Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plugin object has been created for device [ MYRIAD ]\n"
     ]
    }
   ],
   "source": [
    "# create plugin for device\n",
    "plugin = IEPlugin(device=device)\n",
    "print(\"A plugin object has been created for device [\", plugin.device, \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network from Model IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model IR files [ ./nst_vgg19/nst_vgg19-symbol.bin ] and [ ./nst_vgg19/nst_vgg19-symbol.xml ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: from_ir() method of IENetwork is deprecated. Please use IENetwork class constructor to create valid IENetwork instance\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# load network from IR files\n",
    "net = IENetwork.from_ir(model=model_xml, weights=model_bin)\n",
    "print(\"Loaded model IR files [\",model_bin,\"] and [\", model_xml, \"]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model into Device Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model into plugin.  Model input dimensions: n= 1 , c= 3 , h= 224 , w= 224\n"
     ]
    }
   ],
   "source": [
    "# load the model into the plugin\n",
    "exec_net = plugin.load(network=net, num_requests=2)\n",
    "# store name of input and output blobs\n",
    "input_blob = next(iter(net.inputs))\n",
    "output_blob = next(iter(net.outputs))\n",
    "# read the input's dimensions: n=batch size, c=number of channels, h=height, w=width\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "print(\"Loaded model into plugin.  Model input dimensions: n=\",n,\", c=\",c,\", h=\",h,\", w=\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for resizing input image\n",
    "def resizeInputImage(image):\n",
    "    # resize image dimensions form image to model's input w x h\n",
    "    in_frame = cv2.resize(image, (w, h))\n",
    "    # Change data layout from HWC to CHW\n",
    "    in_frame = in_frame.transpose((2, 0, 1))\n",
    "    # reshape to input dimensions\n",
    "    in_frame = in_frame.reshape((n, c, h, w))\n",
    "    return in_frame\n",
    "\n",
    "def processResults(res):\n",
    "    # get output\n",
    "    result = res[output_blob][0]\n",
    "    # Change layout from CxHxW to HxWxC\n",
    "    result = np.swapaxes(result, 0, 2)\n",
    "    result = np.swapaxes(result, 0, 1)\n",
    "    # add RGB mean values to\n",
    "    result = result[::] + (mean_val_r, mean_val_g, mean_val_b)\n",
    "    # Clip RGB values to [0, 255] range\n",
    "    result[result < 0] = 0\n",
    "    result[result > 255] = 255\n",
    "    # Matplotlub expects normilized image with pixel RGB values in range [0,1].\n",
    "    result = result / 255\n",
    "    return result\n",
    "\n",
    "# create function to process and display inference results\n",
    "def processAndDisplayResults(res, orig_input_image, orig_input_path, verbose = True):\n",
    "    # display original input image\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    im_to_show = cv2.cvtColor(orig_input_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(im_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2-openvino) /localdisk/jenkins/workspace/OpenCV/OpenVINO/build/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3ff05427f006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# grab the frame from the threaded video stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mo_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# resize frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0min_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizeInputImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2-openvino) /localdisk/jenkins/workspace/OpenCV/OpenVINO/build/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(<video>)\n",
    "while(cap.isOpened()):\n",
    "    # grab the frame from the threaded video stream\n",
    "    ret, frame = cap.read()\n",
    "    o_image = cv2.resize(frame, (w, h))\n",
    "    # resize frame\n",
    "    in_frame = resizeInputImage(frame)\n",
    "    # inference\n",
    "    res = exec_net.infer(inputs={input_blob: in_frame})\n",
    "    # convert back to image\n",
    "    image = processResults(res)\n",
    "    cv2.imshow(\"Input\", o_image)\n",
    "    cv2.imshow('Output',image)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "# do a bit of cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
